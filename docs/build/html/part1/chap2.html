

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Chapter 2 Intelligent Agents &mdash; ArtificialIntelligence  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Chapter 1 Introduction" href="chap1.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> ArtificialIntelligence
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index1.html">Part 1 Artificial Intelligence</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="chap1.html">Chapter 1 Introduction</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Chapter 2 Intelligent Agents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#agents-and-environments">2.1 Agents and Environments</a></li>
<li class="toctree-l3"><a class="reference internal" href="#good-behavior-the-concept-of-rationality">2.2 Good Behavior: The Concept of Rationality</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#performance-measures">2.2.1 Performance measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="#rationality">2.2.2 Rationality</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#the-nature-of-environments">2.3 The Nature of Environments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#specifying-the-task-environment">2.3.1 Specifying the task environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#properties-of-task-environments">2.3.2 Properties of task environments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#the-structure-of-agents">2.4 The Structure of Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#agent-programs">2.4.1 Agent programs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#simple-reflex-agents">2.4.2 Simple reflex Agents</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ArtificialIntelligence</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index1.html">Part 1 Artificial Intelligence</a> &raquo;</li>
        
      <li>Chapter 2 Intelligent Agents</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/part1/chap2.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\newcommand{\bs}{\boldsymbol}
\newcommand{\dp}{\displaystyle}
\newcommand{\rm}{\mathrm}
\newcommand{\cl}{\mathcal}
\newcommand{\pd}{\partial}\\\newcommand{\cd}{\cdot}
\newcommand{\cds}{\cdots}
\newcommand{\dds}{\ddots}
\newcommand{\lv}{\lVert}
\newcommand{\ol}{\overline}
\newcommand{\ra}{\rightarrow}
\newcommand{\rv}{\rVert}
\newcommand{\seq}{\subseteq}
\newcommand{\vds}{\vdots}
\newcommand{\wh}{\widehat}\\\newcommand{\0}{\boldsymbol{0}}
\newcommand{\1}{\boldsymbol{1}}
\newcommand{\a}{\boldsymbol{\mathrm{a}}}
\newcommand{\b}{\boldsymbol{\mathrm{b}}}
\newcommand{\c}{\boldsymbol{\mathrm{c}}}
\newcommand{\e}{\boldsymbol{\mathrm{e}}}
\newcommand{\f}{\boldsymbol{\mathrm{f}}}
\newcommand{\g}{\boldsymbol{\mathrm{g}}}
\newcommand{\i}{\boldsymbol{\mathrm{i}}}
\newcommand{\j}{\boldsymbol{j}}
\newcommand{\n}{\boldsymbol{\mathrm{n}}}
\newcommand{\p}{\boldsymbol{\mathrm{p}}}
\newcommand{\q}{\boldsymbol{\mathrm{q}}}
\newcommand{\r}{\boldsymbol{\mathrm{r}}}
\newcommand{\u}{\boldsymbol{\mathrm{u}}}
\newcommand{\v}{\boldsymbol{\mathrm{v}}}
\newcommand{\w}{\boldsymbol{w}}
\newcommand{\x}{\boldsymbol{\mathrm{x}}}
\newcommand{\y}{\boldsymbol{\mathrm{y}}}\\\newcommand{\A}{\boldsymbol{\mathrm{A}}}
\newcommand{\B}{\boldsymbol{B}}
\newcommand{\C}{\boldsymbol{C}}
\newcommand{\D}{\boldsymbol{\mathrm{D}}}
\newcommand{\I}{\boldsymbol{\mathrm{I}}}
\newcommand{\K}{\boldsymbol{\mathrm{K}}}
\newcommand{\N}{\boldsymbol{\mathrm{N}}}
\newcommand{\P}{\boldsymbol{\mathrm{P}}}
\newcommand{\S}{\boldsymbol{\mathrm{S}}}
\newcommand{\U}{\boldsymbol{\mathrm{U}}}
\newcommand{\W}{\boldsymbol{\mathrm{W}}}
\newcommand{\X}{\boldsymbol{\mathrm{X}}}\\\newcommand{\R}{\mathbb{R}}\\\newcommand{\ld}{\lambda}
\newcommand{\Ld}{\boldsymbol{\mathrm{\Lambda}}}
\newcommand{\sg}{\sigma}
\newcommand{\Sg}{\boldsymbol{\mathrm{\Sigma}}}
\newcommand{\th}{\theta}\\\newcommand{\mmu}{\boldsymbol{\mu}}\\\newcommand{\bb}{\begin{bmatrix}}
\newcommand{\eb}{\end{bmatrix}}
\newcommand{\bp}{\begin{pmatrix}}
\newcommand{\ep}{\end{pmatrix}}
\newcommand{\bv}{\begin{vmatrix}}
\newcommand{\ev}{\end{vmatrix}}\\\newcommand{\im}{^{-1}}
\newcommand{\pr}{^{\prime}}
\newcommand{\ppr}{^{\prime\prime}}\end{aligned}\end{align} \]</div>
<div class="section" id="chapter-2-intelligent-agents">
<h1>Chapter 2 Intelligent Agents<a class="headerlink" href="#chapter-2-intelligent-agents" title="Permalink to this headline">¶</a></h1>
<div class="section" id="agents-and-environments">
<h2>2.1 Agents and Environments<a class="headerlink" href="#agents-and-environments" title="Permalink to this headline">¶</a></h2>
<p>An <strong>agent</strong> is anything that can be viewed as perceiving its <strong>environment</strong>
through <strong>sensors</strong> and acting upon that environment through <strong>actuators</strong>.</p>
<p>We use the term <strong>percept</strong> to refer to the content an agent’s sensors are perceiving.
An agent’s <strong>percept sequence</strong> is the complete history of everything the agent has ever perceived.
In general, <em>an agent’s choice of action at any given instant can depend on its</em>
<em>built-in knowledge and on the entire percept sequence observed to date, but</em>
<em>not on anything it hasn’t perceived</em>.
Mathematically speaking, we say that an agent’s behavior is described by the
<strong>agent function</strong> that maps any given percept sequence to an action.</p>
<p><em>Internally</em>, the agent function for an artificial agent will be implemented by an <strong>agent program</strong>.
It is important to keep these two ideas distinct.
The agent function is an abstract mathematical description; the agent program is
a concrete implementation, running within some physical system.</p>
</div>
<div class="section" id="good-behavior-the-concept-of-rationality">
<h2>2.2 Good Behavior: The Concept of Rationality<a class="headerlink" href="#good-behavior-the-concept-of-rationality" title="Permalink to this headline">¶</a></h2>
<p>A <strong>rational agent</strong> is one that does the right thing.</p>
<div class="section" id="performance-measures">
<h3>2.2.1 Performance measures<a class="headerlink" href="#performance-measures" title="Permalink to this headline">¶</a></h3>
<p>Moral philosophy has developed several different notions of the “right thing,”
but AI has generally stuck to one notion called <strong>consequentialism</strong>: we
evaluate an agent’s behavior by its consequences.</p>
<p>This notion of desirability is captured by a <strong>performance measure</strong> that
evaluates any given sequence of environment states.</p>
</div>
<div class="section" id="rationality">
<h3>2.2.2 Rationality<a class="headerlink" href="#rationality" title="Permalink to this headline">¶</a></h3>
<p>What is rational at any given time depends on four things:</p>
<ul class="simple">
<li><p>The performance measure that defines the criterion of success.</p></li>
<li><p>The agent’s prior knowledge of the environment.</p></li>
<li><p>The actions that the agent can perform.</p></li>
<li><p>The agent’s percept sequence to date.</p></li>
</ul>
<p><strong>Definition of a rational agent</strong>: <em>For each possible percept sequence, a</em>
<em>rational agent should select an action that is expected to maximize its</em>
<em>performance measure, given the evidence provided by the percept sequence and</em>
<em>whatever built-in knowledge the agent has</em>.</p>
<p>2.2.3 Omniscience, learning, and autonomy</p>
<p>We need to be careful to distinguish between rationality and <strong>omniscience</strong>.
An omniscient agent knows the <em>actual</em> outcome of its actions and can act
accordingly; but omniscience is impossible in reality.</p>
<p>Rationality maximizes <em>expected</em> performance, while perfection maximizes <em>actual</em> performance.</p>
<p>Doing actions <em>in order to modify future percepts</em>—sometimes called <strong>information gathering</strong>.
Our definition requires a rational agent not only to gather information but also
to <strong>learn</strong> as much as possible from what it perceives.</p>
<p>To the extent that an agent relies on the prior knowledge of its designer rather
than on its own percepts and learning processes, we say that the agent lacks
<strong>autonomy</strong>.
A rational agent should be autonomous—it should learn what it can to compensate
for partial or incorrect prior knowledge.</p>
</div>
</div>
<div class="section" id="the-nature-of-environments">
<h2>2.3 The Nature of Environments<a class="headerlink" href="#the-nature-of-environments" title="Permalink to this headline">¶</a></h2>
<div class="section" id="specifying-the-task-environment">
<h3>2.3.1 Specifying the task environment<a class="headerlink" href="#specifying-the-task-environment" title="Permalink to this headline">¶</a></h3>
<p>The <strong>task environment</strong> is composed of <strong>PEAS</strong> (Performance, Environment, Actuators, Sensors).</p>
</div>
<div class="section" id="properties-of-task-environments">
<h3>2.3.2 Properties of task environments<a class="headerlink" href="#properties-of-task-environments" title="Permalink to this headline">¶</a></h3>
<p><strong>FULLY OBSERVABLE VS. PARTIALLY OBSERVABLE</strong>: If an agent’s sensors give it
access to the complete state of the environment at each point in time, then we
say that the task environment is fully observable.
An environment might be partially observable because of noisy and inaccurate
sensors or because parts of the state are simply missing from the sensor data.
If the agent has no sensors at all then the environment is <strong>unobservable</strong>.</p>
<p><strong>SINGLE-AGENT VS. MULTIAGENT</strong>: The agent-design problems in multiagent
environments are often quite different from those in single-agent environments.</p>
<p><strong>DETERMINISTIC VS. NONDETERMINISTIC</strong>: If the next state of the environment is
completely determined by the current state and the action executed by the
agent(s), then we say the environment is deterministic; otherwise, it is
nondeterministic.</p>
<p><strong>EPISODIC VS. SEQUENTIAL</strong>: In an episodic task environment, the agent’s
experience is divided into atomic episodes.
Crucially, the next episode does not depend on the actions taken in previous episodes.
In sequential environments, on the other hand, the current decision could affect all future decisions.</p>
<p><strong>STATIC VS. DYNAMIC</strong>: If the environment can change while an agent is
deliberating, then we say the environment is dynamic for that agent; otherwise,
it is static.
If the environment itself does not change with the passage of time but the
agent’s performance score does, then we say the environment is <strong>semidynamic</strong>.</p>
<p><strong>DISCRETE VS. CONTINUOUS</strong>: The discrete/continuous distinction applies to the
<em>state</em> of the environment, to the way <em>time</em> is handled, and to the <em>percepts</em>
and <em>actions</em> of the agent.</p>
<p><strong>KNOWN VS. UNKNOWN</strong>: In a known environment, the outcomes (or outcome
probabilities if the environment is nondeterministic) for all actions are given.
Obviously, if the environment is unknown, the agent will have to learn how it works in order to make good decisions.</p>
<p>The performance measure itself may be unknown, either because the designer is
not sure how to write it down correctly or because the ultimate user—whose
preferences matter—is not known.
The hardest case is <em>partially observable</em>, <em>multiagent</em>, <em>nondeterministic</em>,
<em>sequential</em>, <em>dynamic</em>, <em>continuous</em>, and <em>unknown</em>.</p>
</div>
</div>
<div class="section" id="the-structure-of-agents">
<h2>2.4 The Structure of Agents<a class="headerlink" href="#the-structure-of-agents" title="Permalink to this headline">¶</a></h2>
<p>The job of AI is to design an <strong>agent program</strong> that implements the agent function—the mapping from percepts to actions.
We assume this program will run on some sort of computing device with physical
sensors and actuators—we call this the <strong>agent architecture</strong>:</p>
<blockquote>
<div><p><em>agent</em> = <em>architecture</em> + <em>program</em>.</p>
</div></blockquote>
<div class="section" id="agent-programs">
<h3>2.4.1 Agent programs<a class="headerlink" href="#agent-programs" title="Permalink to this headline">¶</a></h3>
<img alt="../_images/Figure2.7.png" src="../_images/Figure2.7.png" />
<p>The daunting size of these tables means that (a) no physical agent in this
universe will have the space to store the table; (b) the designer would not have
time to create the table; and (c) no agent could ever learn all the right table
entries from its experience.</p>
<p><em>The key challenge for AI is to find out how to write programs that, to the</em>
<em>extent possible, produce rational behavior from a smallish program rather than</em>
<em>from a vast table</em>.</p>
</div>
<div class="section" id="simple-reflex-agents">
<h3>2.4.2 Simple reflex Agents<a class="headerlink" href="#simple-reflex-agents" title="Permalink to this headline">¶</a></h3>
<p>The simplest kind of agent is the <strong>simple reflex agent</strong>.
These agents select actions on the basis of the <em>current</em> percept, ignoring the rest of the percept history.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="chap1.html" class="btn btn-neutral float-left" title="Chapter 1 Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Ziniu Yu.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>